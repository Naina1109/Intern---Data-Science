{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's import all the required libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's load the drivers and URL\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's call the Function Definition\n",
    "\n",
    "#Let's enter the details in the search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Let's enter the job title and location \n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Azure Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr Manager I - Data Analyst (MINT)',\n",
       " 'Data Analyst (SQL, Excel, R/Python, Dashboards, PowerBI) - Contract',\n",
       " 'Specialist I / II Data Analyst',\n",
       " 'Data Analyst with Marketing Analytics-Capco',\n",
       " 'Inviting Business Analyst –Data Science and Insights Bangalore',\n",
       " 'Junior Data Analyst']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Devalapur)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Capgemini Technology Services India Limited',\n",
       " 'RedLock, Inc',\n",
       " 'Super India Tech Mark',\n",
       " 'tech mahindra ltd',\n",
       " 'CONDUENT BUSINESS SERVICES INDIA LLP',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'WEIWO Communication Pvt. Ltd.',\n",
       " 'Cerner',\n",
       " 'Cerner Corporation',\n",
       " 'ExecBoardinAsia',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Philips India Limited',\n",
       " 'Capco Technologies Pvt Ltd',\n",
       " 'GENPACT India Private Limited',\n",
       " 'Happy Marketer Private Ltd']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-0 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-2 Yrs',\n",
       " '1,25,000 - 2,25,000 PA.',\n",
       " 'Bangalore/Bengaluru(Devalapur)',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-2 Yrs',\n",
       " '4,50,000 - 5,00,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '2-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '11-15 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-5 Yrs',\n",
       " '5,50,000 - 6,50,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " '7,00,000 - 17,00,000 PA.',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " '0-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-3 Yrs',\n",
       " '3,00,000 - 7,00,000 PA.',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " '6-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-0 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-2 Yrs',\n",
       " '1,25,000 - 2,25,000 PA.',\n",
       " 'Bangalore/Bengaluru(Devalapur)',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-2 Yrs',\n",
       " '4,50,000 - 5,00,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '2-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-8 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '11-15 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-5 Yrs',\n",
       " '5,50,000 - 6,50,000 PA.',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-9 Yrs',\n",
       " '7,00,000 - 17,00,000 PA.',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " '0-4 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '1-3 Yrs',\n",
       " '3,00,000 - 7,00,000 PA.',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the exoerience required\n",
    "\n",
    "experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "for i in experience:\n",
    "    experience_required.append(i.text)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azure Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RedLock, Inc</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>1,25,000 - 2,25,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Job Title                    Job Location  \\\n",
       "0  Azure Data Analyst             Bangalore/Bengaluru   \n",
       "1        Data Analyst             Bangalore/Bengaluru   \n",
       "2        Data Analyst  Bangalore/Bengaluru(Devalapur)   \n",
       "3        Data Analyst             Bangalore/Bengaluru   \n",
       "4        Data Analyst             Bangalore/Bengaluru   \n",
       "5        Data Analyst             Bangalore/Bengaluru   \n",
       "6        Data Analyst             Bangalore/Bengaluru   \n",
       "7        Data Analyst             Bangalore/Bengaluru   \n",
       "8        Data Analyst             Bangalore/Bengaluru   \n",
       "9        Data Analyst             Bangalore/Bengaluru   \n",
       "\n",
       "                                  Company Name             Experience Required  \n",
       "0  Capgemini Technology Services India Limited                         6-8 Yrs  \n",
       "1                                 RedLock, Inc                   Not disclosed  \n",
       "2                        Super India Tech Mark             Bangalore/Bengaluru  \n",
       "3                            tech mahindra ltd                         0-0 Yrs  \n",
       "4         CONDUENT BUSINESS SERVICES INDIA LLP                   Not disclosed  \n",
       "5      GlaxoSmithKline Pharmaceuticals Limited             Bangalore/Bengaluru  \n",
       "6                     Myntra Designs Pvt. Ltd.                         0-2 Yrs  \n",
       "7                     Myntra Designs Pvt. Ltd.         1,25,000 - 2,25,000 PA.  \n",
       "8                     Myntra Designs Pvt. Ltd.  Bangalore/Bengaluru(Devalapur)  \n",
       "9                     Myntra Designs Pvt. Ltd.                         4-8 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "\n",
    "data_analyst_jobs=pd.DataFrame({})\n",
    "data_analyst_jobs['Job Title']=job_title[0:10]    \n",
    "data_analyst_jobs['Job Location']=job_location[0:10]\n",
    "data_analyst_jobs['Company Name']=company_name[0:10]\n",
    "data_analyst_jobs['Experience Required']=experience_required[0:10]\n",
    "data_analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's load the drivers and URL\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's call the Function Definition\n",
    "\n",
    "#Let's navigate to search column\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Let's enter the job title and location\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Opportunity For Data Scientist Internship - Bengaluru',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist || Data Analyst || Data science',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'GAMMA Lead Data Scientist',\n",
       " 'DBCG IND - GAMMA Senior Data Scientist',\n",
       " 'Data Scientist/Senior Data Scientist',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Global Medical Data Scientist',\n",
       " 'Associate Data Scientist - CRM & Loyalty',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Analyst / ML & AI Engineer / Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Jr. Data Scientist',\n",
       " 'Senior Data Scientist (Machine Vision solutions)',\n",
       " 'Data Scientist - BFSI',\n",
       " 'Senior Data Scientist/Manager Data Scientist',\n",
       " 'Excellent Opportunity Of Data Scientist For CMMI Level 5 Company']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job tile\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Navi Mumbai, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Sector 1 HSR Layout)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Noida, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the job location\n",
    "\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CronJ IT Technologies Private Limited',\n",
       " 'Corner Stone Solutions',\n",
       " 'AugmatrixGo',\n",
       " 'Inspiration Manpower Consultancy Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Boston Consulting Group',\n",
       " 'Boston Consulting Group',\n",
       " 'GANIT BUSINESS SOLUTIONS PRIVATE LIMITED',\n",
       " 'CES Ltd.',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'CHANDRA PUMPS',\n",
       " 'DUN & BRADSTREET INFORMATION SERVICES INDIA PRIVATE LIMITED',\n",
       " 'Redcan IT Services LLP',\n",
       " 'Multi Recruit',\n",
       " 'ONX Software Systems Pvt Ltd',\n",
       " 'Black Turtle India Pvt Ltd',\n",
       " 'Novitas Infotech',\n",
       " 'Skyleaf Consultants']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the company name\n",
    "\n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description\\nResponsibilities and Duties\\nCreate innovative solutions using data across sales, health care and related fields for building object detection models, classification models, recommendation engine, sentiment analysis etc.\\nFamiliarity with deep learning algorithms and frameworks like TensorFlow, Pytorch, Keras.\\nGood to go with NLP and NLTK\\nDay-to-day responsibilities include use, customize and create algorithms/models for specific tasks in data science.\\nGet exposed to and work on cutting-edge products based on ML and AI to create innovative industry solutions.\\nWork on real-life projects involving Computer Vision, NLP and other AI techniques,\\nUsing innovative ideas to collect, curate or synthesize data.\\nModel the problem into an ML/DL framework.\\nDeploy models to real time staging servers.\\nFlexibility in working independently and do needful research whenever required.\\nRequired Experience, Skills and Qualifications\\nKnowledge of Python\\nKnowledge in libraries like OpenCV, Scikit Learn, NumPy etc.\\nScripting\\nUnderstanding of different frameworks like Pytorch, TensorFlow, Keras etc.\\nKnowledge on NLP\\nGood Knowledge on OOP and programing in python adapting to requirement\\nUnderstanding of AWS.\\nUnderstanding of any annotation tool.\\nAbility to write robust and testable code.\\nStrong knowledge in computer science fundamentals, algorithms, mathematics, linear algebra, probability and statistics.\\nStrong communication skills.\\nAn analytical mind with problem-solving abilities.\\nDegree in Computer Science, Mathematics, Computational Linguistics or similar field.\\nRoleTrainee\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nTensorflowJavaC++CphythonData StructuresArtificial IntelligenceMachine LearningMATLABsoftware DeveloperNLPAlgorithmsFresherComputer VisionLinear Algebra',\n",
       " 'Job description\\nLocation - Bangalore / Bengaluru\\nDuration- 6 Months\\nResponsibilities and Duties\\nCreate innovative solutions using data across sales, health care and related fields for building object detection models, chatbots, classification models etc.\\nFamiliarity with deep learning algorithms and frameworks like Pytorch, Keras, TensorFlow.\\nGood to go with NLP and NLTK\\nDay-to-day responsibilities include use, customize and create algorithms for specific tasks in data science.\\nGet exposed to and work on cutting-edge products based on ML and AI to create innovative industry solutions..\\nWork on real-life projects involving Computer Vision, NLP and other AI techniques,\\nUsing innovative ideas to collect, curate or synthesize data.\\nModel the problem into an ML/DL framework.\\nDeploy models to real time staging servers.\\nFlexibility in working independently and do needful research whenever required.\\nRequired Experience, Skills and Qualifications\\nKnowledge of Python\\nKnowledge in libraries like OpenCV, Scikit Learn, NumPy etc.\\nUnderstanding of different frameworks like Pytorch, TensorFlow, Keras etc.\\nKnowledge on NLP\\nGood Knowledge on OOP and programing in python adapting to requirement\\nUnderstanding of aws\\nUnderstanding of any annotation tool\\nAbility to write robust and testable code.\\nStrong knowledge in computer science fundamentals, algorithms, mathematics, linear algebra, probability and statistics.\\nStrong communication skills.\\nAn analytical mind with problem-solving abilities.\\nDegree in Computer Science, Mathematics, Computational Linguistics or similar field.\\nQualification:\\n\\nLooking for IIT, IIIT IISc, NIT, BIT & Equivalent colleges (Preferred)\\nRoleSoftware Developer\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nKey Skills\\nNLPOpencvArtificial Intelligence\\nData ScienceRtensorflowAlgorithmsMATLABLinear AlgebraPython\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\n\\n- Selecting features, building and optimizing classifiers using machine learning techniques\\n\\n- Data mining using state-of-the-art methods\\n\\n- Enhancing data collection procedures to include information that is relevant for building analytic systems\\n\\n- Processing, cleansing, and verifying the integrity of data used for analysis\\n\\n- Doing ad-hoc analysis and presenting results in a clear manner\\n\\n- Creating automated anomaly detection systems and constant tracking of its performance\\n\\nSkills Required :\\n\\n- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n\\n- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc\\n\\n- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization\\n\\n- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks\\n\\n- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable\\n\\n- Proficiency in using query languages such as SQL, Hive, Pig\\n\\n- Good applied statistics skills, such as distributions, statistical testing, regression, etc.\\n\\n- Good scripting and programming skills\\n\\n- Data-oriented personality\\n\\n- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS\\nRoleData Analyst\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nHiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig',\n",
       " 'Job description\\nJob description\\nJob Summary and Key Responsibilities\\nManage, architect, and analyze big data to build data driven business insights and high impact data models to generate significant business value. Create models and processes to collect, distill and interpret data with a view to aid better, more informed decision making. Examine and explore data from multiple disparate sources with the goal of discovering insights which in turn can provide competitive advantage for our stakeholders.\\nThe role involves but not limited to the following:\\nCreate insights from predictive statistical modeling, mathematical knowledge, tools, and techniques to solve complex problems and deliver value\\nCollaborate with Accenture teams to address business issues and influence change using strategy, industry, and analytical skills\\nDeliver large-scale programs that integrate processes with technology to help clients achieve high performance\\nMining and EDA of large datasets to assist in developing analytics solution\\nIndividual contributor and/or oversees a small work effort\\nWork with minimal supervision on daily tasks and moderate level of instruction on new assignments\\nKey Skills\\nMust Have\\nAnalytical skills\\nKnowledge of statistical techniques and machine learning algorithms\\nKnowledge of analysis tools like R, Python\\nAdvanced Excel, PowerPoint skills\\nAdvanced communication (written and oral) and strong interpersonal skills\\nAbility to work cross-culturally\\nGood to have\\nKnowledge on Google Cloud Platform\\nHuman Resources experience\\nAdditional Accenture HR systems experience\\nUnderstanding of Text analysis, VBA, Java, Python, .Net and visualization tools like Qliksense, Qlikview, Tableau will be an added advantage\\nInterested Candidates\\n\\n\\nPlease Contact: Geethanjali\\n9900044693\\nhr1@inspirationmanpower.co.in\\n\\nRoleData Analyst\\nIndustry TypeBPO, Call Centre, ITeS\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nData ScienceJavaREDAStatistical ModelingData AnalysisBig DataTableauMachine LearningPython',\n",
       " 'Not Available',\n",
       " 'Job description\\n  Practice Area Profile\\nBCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology.\\nWhat Youll Do\\nWe are seeking a strong candidate with advanced analytics experience to fill an exciting Lead Data Scientist (LDS) position within BCG Gamma. The LDS is a valuable expert in Data Science and Analytics and will design and build analytics methodologies, solutions, and products to deliver value to BCGs clients in collaboration with case teams. Exceptional candidates will also show an analytical curiosity, going beyond the immediate requirements of the project to find deep insights that others have missed. They will ask questions about outliers, seek to understand the fundamental drivers of advantage and look for clues that may change the basis of competition.\\nThe LDS will be involved in all aspects of advanced analytics, from helping to create relevant products and service offerings by working with priority global Practice Areas, to leading and executing analytics work and continuing to expand the analytical foundation and competitive value proposition. The LDS will collaborate directly client and wider BCG case teams and will manage the analytics components of client deliverables. The LDS is responsible for clarifying initial objectives, setting up analytics work plan and methodology, organizing the data scientist members of the team, quality assurance, and managing scope and work planning throughout the project.\\nThe LDS is expected to provide mentoring, coaching, and career development to (senior) analytics associate and data scientist team members on both a formal and informal basis.\\nAs the field of advanced analytics is rapidly evolving, the LDS is responsible for staying current on leading-edge business applications, tools and approaches, proactively working with the Analytics\\nLeadership to enhance offerings that deliver competitive advantage to BCG.\\n\\nKEY COMPETENCIES:\\nDeep Technical and Data Science Expertise : The successful candidate will have a wealth of experience with applying advanced analytics to a variety of business situations, such that they can efficiently and effectively advise multiple teams on the best path to uncovering critical insights for clients.\\nExperience in core analytics methods (one or more of the following): Statistics (t-tests, ANOVA), variable reduction (FA, PCA), Segmentation/clustering techniques , Geographic cluster recognition and manipulation techniques, Predictive modeling: e.g. logistic regression, linear regression, Network analysis (location-allocation, travelling sales person, vehicle routing problem), Time series analysis: e.g. ARIMA, VAR, etc., Machine learning: e.g. LCA, Random Forest, neural networks, Spatio-temporal analysis, Time series analysis (ARIMA, VAR, etc.), Text mining unstructured data analytics, Simulation: e.g. MC, dynamic, discrete event, Optimization: e.g. linear programming, heuristic\\nFamiliarity with a broad base of analytics tools (one or more of the following): Data management: e.g. Excel, SQL, PostGRESql, Hadoop/Hive, Alteryx, Analytics platforms: e.g. SAS, R, RapidMiner, SPSS, Data visualization: e.g. Tableau, GIS toolkits (ESRI, Quantum GIS, MapInfo or similar), ESRI Network Analyst, RouteSmart, RoadNet or similar, GPS data analysis a plus, Programming and/or scripting experience: e.g. Python, C#, VBA, Java, Perl, etc.\\nExperience in applied analytics for business problem solving : Eg. Extensive experience building analytical solutions for (one or more of the following), Pricing and promotional effectiveness, Delivery fleet consolidation, Loyalty program effectiveness, Network real estate reorganization, Customer segmentation and targeting, Delivery footprint/territory expansion (or reduction), Customer LTV maximization, Cost modeling of transportation logistics operations, Churn prevention, Strong project management skills, Others a plus\\nAnalytical and Conceptual thinking: A successful candidate will be able to conceptualize business problems and drive frameworks. The LDS will produce leading edge business models and must be able to work in a hypothesis-based environment where inductive rather than deductive thinking is the norm.\\nEngagement Management and Work with Case Teams: The successful candidate will have demonstrated ability to manage engagements, client relationships, provide thought leadership to teams and able to act as a full member of a BCG project team. They must own analytical modules from work planning to creating impact. He/she must scope, manage and lead work for data science teams, providing expertise on methodology of advanced analytics. Strong presence, strong collaborator and leadership skills and ability to operate effectively in a matrix organization are a must.\\nClient Relationship Management: The candidate with have a demonstrated ability to communicate effectively and professionally with clients, delivering impactful solutions and presenting work in a concise and thoughtful manner, while demonstrating technical expertise (fluency in English is required). Strong business focus with experience with 80/20 approaches.\\nAnalytics Innovation: Must be an autonomous self starter with a passion for analytics and problem solving. He/she will help build new Analytics service offerings that grow our portfolio of products and will captures proprietary content as well as analytics insights to the knowledge infrastructure. The candidate will support the creation of proposal/selling documents and provide perspective on relevant Analytics value propositions.\\n\\nPersonnel Development: The successful candidate will have demonstrated ability to guide junior data scientists in their consulting skill sets, motivate them, and build the company s foundation for future growth. This will take place in both formal and ad-hoc settings.\\n\\n\\n7 years of relevant industry work experience in a field linked to business analytics, statistics or geo- statistics, operations research, geography, applied mathematics, computer science, engineering, or related field Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues. Strong record of professional accomplishment and leadership. Demonstrated ability to lead and manage projects and teams.\\nRoleSoftware Developer\\nIndustry TypeStrategy, Management Consulting Firms\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nData analysisOperations researchdata scienceData managementBusiness analyticsConsultingManagement consultingBusiness strategySPSSSQL',\n",
       " 'Job description\\n    What Youll Do\\n\\nWe re looking for a passionate and talented Senior Data Scientist to join our rapidly growing team.\\nIn this role, you ll have the chance to roll up your sleeves and apply data science methods and analytics to real-world business situations across a variety of industries.\\nAs the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on leading-edge business applications, tools and approaches, proactively working with the Analytics Leadership to enhance offerings that\\ndeliver competitive advantage to BCG.\\nSuccessful candidates are intellectually curious builders who are biased toward action, scrappy, and communicative.\\nYou will also get the chance to travel: we have clients across the globe Make sure your passport is ready to go!\\n \\n\\n\\nWHO YOU ARE. YOU:\\nHave deep technical and Data Science expertise: The successful candidate will have a wealth of experience with applying advanced analytics to a variety of business situations, such that they can efficiently and effectively advise multiple teams on the best path to uncovering critical insights for clients.\\nAre an autonomous self-starter with a passion for analytics and problem solving. You will help build new Analytics service offerings that grow our portfolio of products and will captures proprietary content, and support the creation of proposal/selling documents.\\nAre comfortable managing engagements, client relationships, and acting as a thought Leader. Strong presence, strong collaborator and leadership skills and ability to operate effectively in a matrix organization are a must.\\nLove building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)\\nHave significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data; as well as a deep understanding of modern machine learning techniques and their mathematical underpinnings, and are able to translate this into business implications for our clients\\nHave strong project management skills\\nMaster s Degree with significant relevant experience providing advanced analytics solutions, or relevant PhD in computer science, applied mathematics, statistics, machine learning, or a related data centric field.\\nDemonstrated deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.\\nStrong record of professional accomplishment and leadership.\\nFluency in at least one scripting language (e.g. Python, R)\\nFluency in English and local office language are required\\nFast-paced, intellectually intense, service-oriented environment\\nPosition is located in either Chennai, Mumbai, Delhi-NCR or Bengaluru\\nExpect up to 60-80% of time spent traveling\\nRoleSoftware Developer\\nIndustry TypeStrategy, Management Consulting Firms\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nComputer scienceadvanced analyticsSDSdata scienceArtificial IntelligenceProject managementMachine learningManagement consultingBusiness strategyPython',\n",
       " 'Job description\\n\\nAbout Ganit Inc\\n\\nFounded by senior industry experts, Ganit is the fastest-growing data science company in Chennai with offices in Bengaluru, Mumbai & New Jersey.\\nGanit has flipped the data science value chain as we do not start with a technique but for us, consumption comes first. With this philosophy, we have successfully scaled from being a small start-up to a 200 resource company with clients in the US, Singapore, Africa, UAE, and India.\\nWe are looking for experienced data enthusiasts who can make the data talk to them.\\n\\nWhat you will be doing.\\n\\nUnderstand business problems and translate business requirements into technical requirements.\\n\\nConduct complex data analysis to ensure data quality & reliability i.e., make the data talk by extracting, preparing, and transforming it.\\n\\nIdentify, develop and implement statistical techniques and algorithms to address business challenges and add value to the organization.\\n\\nGather requirements and communicate findings in the form of a meaningful story with the Stakeholders.\\n\\nBuild & implement data models using predictive modeling techniques. Interact with clients and provide support for queries and delivery adoption.\\n\\nLead and mentor data analysts.\\n\\nWhat we are looking for:\\nApart from your love for data and ability to code even while sleeping you would need the following.\\n\\nMinimum of 04 years of experience in designing and delivery of data science solutions.\\n\\nYou should have successful projects in Manufacturing in your kitty to show-off. (Experience on manufacturing analytics is a MUST)\\n\\nDeep understanding of various statistical techniques, mathematical models, and algorithms to start the conversation with the data in hand.\\n\\nAbility to choose the right model for the data and translate that into a code using R, Python, VBA, SQL, etc.\\n\\nBachelors/Masters degree in Engineering/Technology or\\nMBA from Tier-1 B School or\\nMSc. in Statistics or Mathematics\\n\\nWhat is in it for you:\\n\\nBe a part of building the biggest brand in Data science.\\nAn opportunity to be a part of a young and energetic team with a strong pedigree.\\nWork on awesome projects across industries and learn from the best in the industry, while growing at a hyper rate.\\nRoleData Analyst\\nIndustry TypeAutomobile, Auto Anciliary, Auto Components\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nPredictive ModelingManufacturing AnalyticsPython\\nData ScienceRData QualityAlgorithmsVBAData AnalysisAnamoly detectionStatisticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\nMust have strong Python Programming Skills\\nStrong analytical & algorithm development skills\\nLogical and Analytical skills must be really strong\\nMust have worked in DeepLearning Efforts - Especially computer vision.\\nMust have experinece with Object Detection - Custom model training for Object detection\\nShould have experience with atleast one or more of these - Tensorflow, Keras, PyTorch\\n\\nPrimary Skills - Python + tensorflow - Keras / PyTorch, OpenCV\\nPerks and Benefits\\n\\nKindly share your resume to kandavelkumar.lakshmanan @cesltd.com\\n\\nRoleTechnical Architect\\nIndustry TypeIT-Software, Software Services\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nTensorflowObject DetectionAlgorithm DevelopmentAnalytical SkillsProgrammingMachine LearningDeep LearningPytorchData ScienceROpencvKerasComputer VisionPython',\n",
       " 'Not Available']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scrape the detail job description\n",
    "\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")\n",
    "job_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Detailed Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>Job description\\nResponsibilities and Duties\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>Job description\\nLocation - Bangalore / Bengal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Job description\\nJob description\\nJob Summary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GAMMA Lead Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Job description\\n  Practice Area Profile\\nBCG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Job description\\n    What Youll Do\\n\\nWe re lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Job description\\n\\nAbout Ganit Inc\\n\\nFounded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3     Data Scientist || Data Analyst || Data science   \n",
       "4                        Data Scientist - IBM Garage   \n",
       "5                          GAMMA Lead Data Scientist   \n",
       "6             DBCG IND - GAMMA Senior Data Scientist   \n",
       "7               Data Scientist/Senior Data Scientist   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9                      Global Medical Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "4  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "8  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "2                                 AugmatrixGo   \n",
       "3  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "4                      IBM India Pvt. Limited   \n",
       "5                     Boston Consulting Group   \n",
       "6                     Boston Consulting Group   \n",
       "7    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "8                                    CES Ltd.   \n",
       "9     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "\n",
       "                            Detailed Job Description  \n",
       "0  Job description\\nResponsibilities and Duties\\n...  \n",
       "1  Job description\\nLocation - Bangalore / Bengal...  \n",
       "2  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "3  Job description\\nJob description\\nJob Summary ...  \n",
       "4                                      Not Available  \n",
       "5  Job description\\n  Practice Area Profile\\nBCG ...  \n",
       "6  Job description\\n    What Youll Do\\n\\nWe re lo...  \n",
       "7  Job description\\n\\nAbout Ganit Inc\\n\\nFounded ...  \n",
       "8  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "9                                      Not Available  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "\n",
    "data_scientist_jobs=pd.DataFrame({})\n",
    "data_scientist_jobs['Job Title']=job_title[0:10]    \n",
    "data_scientist_jobs['Job Location']=job_location[0:10]\n",
    "data_scientist_jobs['Company Name']=company_name[0:10]\n",
    "data_scientist_jobs['Detailed Job Description']=job_description[0:10]\n",
    "data_scientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: In this question you have to scrape data using the filters available on the webpage\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def jobs_data_Scientist(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    ds_job_title=[]\n",
    "    ds_company_name=[]\n",
    "    ds_location=[]\n",
    "    ds_experience=[]\n",
    "    ds_salary=[]\n",
    "    \n",
    "    #Let's navigate to the search column\n",
    "    driver.find_element_by_xpath('//input[@class=\"sugInp\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//button[@class=\"btn\"]').click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Let's create filter for job location\n",
    "    driver.find_element_by_xpath('//span[@title=\"Delhi / NCR\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create filter for salary\n",
    "    driver.find_element_by_xpath('//span[@title=\"3-6 Lakhs\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's scrape the job tile\n",
    "    job_titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in job_titles:\n",
    "        ds_job_title.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company name\n",
    "    company_name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for i in company_name:\n",
    "        ds_company_name.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company location    \n",
    "    location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for i in location:\n",
    "        ds_location.append(i.text)\n",
    "    \n",
    "        \n",
    "    # Let's scrape the experience\n",
    "    experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "    for i in experience:\n",
    "        ds_experience.append(i.text)\n",
    "    \n",
    "    # Let's scrape the salary\n",
    "    salary=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "    for i in salary:\n",
    "        ds_salary.append(i.text)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    ds_jobs=pd.DataFrame({})\n",
    "    ds_jobs['Job Title']=ds_job_title[0:10]\n",
    "    ds_jobs['Company Name']=ds_company_name[0:10]\n",
    "    ds_jobs['Job Location']=ds_location[0:10]\n",
    "    ds_jobs['Experience']=ds_experience[0:10]\n",
    "    return ds_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Required- Data Scientist (NLP)-Axis Bank - 6 m...</td>\n",
       "      <td>Axis Bank Limited</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title            Company Name  \\\n",
       "0                        Data Scientist - IBM Garage  IBM India Pvt. Limited   \n",
       "1  Data Scientist/Data Analyst - Python/Machine L...          Change leaders   \n",
       "2            Females Required- Data Scientist- Noida                Randstad   \n",
       "3                                     Data Scientist        Amity University   \n",
       "4         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "5         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "6  Data Scientist - Python / Machine Learning / T...     FUTURES AND CAREERS   \n",
       "7         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "8  Required- Data Scientist (NLP)-Axis Bank - 6 m...       Axis Bank Limited   \n",
       "9  Data Scientist - Python / Machine Learning / T...     FUTURES AND CAREERS   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "1                                  Mumbai, Ghaziabad   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "3                  Ghaziabad, Faridabad, Delhi / NCR   \n",
       "4  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "6  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "7  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "8  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "\n",
       "                                          Experience  \n",
       "0                                            5-8 Yrs  \n",
       "1                                      Not disclosed  \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "3                                           5-10 Yrs  \n",
       "4                                      Not disclosed  \n",
       "5                                  Mumbai, Ghaziabad  \n",
       "6                                            3-7 Yrs  \n",
       "7                                      Not disclosed  \n",
       "8               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "9                                            6-8 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "jobs_data_Scientist('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def glass_door_job(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    job_title=[]\n",
    "    company_name=[]\n",
    "    rating=[]\n",
    "    days=[]\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # If we visit the glassdoor page we will observe that, to navigate into the page we have to do the login\n",
    "    # Let's click on the sign-in butoon for logining\n",
    "    driver.find_element_by_xpath('//div[@class=\"locked-home-sign-in\"]').click()\n",
    "    \n",
    "    #Let's enter the demo login details\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('lognelugni@biyac.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('March@2021')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's maximize the window size because there are some text font size is will has other element details in short window\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's fill the requied details in search column and click search\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's search the desired detail which we hve entered\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    jobs=driver.find_elements_by_xpath('//article[@id=\"MainCol\"]/div/ul/li')\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Let's scrape the data\n",
    "        job_title.append((driver.find_element_by_xpath('//div[@class=\"css-1vg6q84 e1tk4kwz4\"]')).text)\n",
    "        company_name.append((driver.find_element_by_xpath('//div[@class=\"css-87uc0g e1tk4kwz1\"]')).text.replace('\\n',''))\n",
    "        try:\n",
    "            rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text)\n",
    "        except:\n",
    "            rating.append('NA')\n",
    "        try:\n",
    "            days.append((driver.find_element_by_xpath('//div[@data-test=\"job-age\"]')).text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    job_glass_door=pd.DataFrame({})\n",
    "    job_glass_door['Job Title']=job_title[0:10]\n",
    "    job_glass_door['Company Name']=company_name[0:10]\n",
    "    job_glass_door['Rating of the Company']=rating[0:10]\n",
    "    job_glass_door['Job Posted Days Ago']=days[0:10]\n",
    "    return job_glass_door       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Rating of the Company</th>\n",
       "      <th>Job Posted Days Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>JLL4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Techlive5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>NA</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analytics Internship</td>\n",
       "      <td>Decision Tree Analytics And Services5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Ohmyhome3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Job Title                             Company Name  \\\n",
       "0             Data Scientist                        Biz2Credit Inc3.8   \n",
       "1             Data Scientist                                   JLL4.0   \n",
       "2      Data Scientist Intern             Salasar New Age Technologies   \n",
       "3             Data Scientist                              Techlive5.0   \n",
       "4             Data Scientist             Salasar New Age Technologies   \n",
       "5             Data Scientist                                 Adobe4.4   \n",
       "6             Data Scientist                                 Adobe4.4   \n",
       "7             Data Scientist                          SearchUrCollege   \n",
       "8  Data Analytics Internship  Decision Tree Analytics And Services5.0   \n",
       "9              Data Engineer                              Ohmyhome3.0   \n",
       "\n",
       "  Rating of the Company Job Posted Days Ago  \n",
       "0                   3.8                30d+  \n",
       "1                   4.0                30d+  \n",
       "2                    NA                30d+  \n",
       "3                   5.0                30d+  \n",
       "4                    NA                30d+  \n",
       "5                   4.4                30d+  \n",
       "6                   4.4                30d+  \n",
       "7                    NA                30d+  \n",
       "8                   5.0                30d+  \n",
       "9                   3.0                30d+  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "glass_door_job('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def gd_salary(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    gd_min_salary=[]\n",
    "    gd_max_salary=[]\n",
    "    gd_avg_salary=[]\n",
    "    gd_company_name=[]\n",
    "    gd_rating=[]\n",
    "\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #Let's navigate to search bar and then type the Data Scientist job, location Noida and then click search button\n",
    "    driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys('Noida (India)')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "     # search the element for required details\n",
    "    companies=driver.find_elements_by_xpath('//div[@data-test=\"job-info\"]/p[2]')\n",
    "    avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')\n",
    "    min_salary= driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")\n",
    "    max_salary =driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "    rating='NA'\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    for i in companies:\n",
    "        gd_company_name.append(i.text)\n",
    "    for i in avg_salary:\n",
    "        gd_avg_salary.append(i.text)\n",
    "    for i in min_salary:\n",
    "        gd_min_salary.append(i.text)\n",
    "    for i in max_salary:\n",
    "        gd_max_salary.append(i.text)\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    salaries=pd.DataFrame({})\n",
    "    salaries['Company Name']=gd_company_name[:10]\n",
    "    salaries['Avgerage Salary']=gd_avg_salary[:10]\n",
    "    salaries['Minimum Salary']=gd_min_salary[:10]\n",
    "    salaries['Maximum Salary']=gd_max_salary[:10]\n",
    "    salaries['Rating of the Company']=rating[:10]\n",
    "    return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Avgerage Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Rating of the Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 5,97,967</td>\n",
       "      <td>₹333K</td>\n",
       "      <td>₹1,080K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,12,243</td>\n",
       "      <td>₹560K</td>\n",
       "      <td>₹2,147K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,12,741</td>\n",
       "      <td>₹436K</td>\n",
       "      <td>₹11,274K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,37,972</td>\n",
       "      <td>₹569K</td>\n",
       "      <td>₹2,648K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,15,984</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,565K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,41,900</td>\n",
       "      <td>₹1,037K</td>\n",
       "      <td>₹1,500K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,90,812</td>\n",
       "      <td>₹487K</td>\n",
       "      <td>₹1,421K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹ 11,81,047</td>\n",
       "      <td>₹602K</td>\n",
       "      <td>₹1,644K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 9,89,924</td>\n",
       "      <td>₹196K</td>\n",
       "      <td>₹1,755K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,73,127</td>\n",
       "      <td>₹558K</td>\n",
       "      <td>₹1,500K</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Avgerage Salary Minimum Salary Maximum Salary  \\\n",
       "0  Tata Consultancy Services      ₹ 5,97,967          ₹333K        ₹1,080K   \n",
       "1                  Accenture     ₹ 11,12,243          ₹560K        ₹2,147K   \n",
       "2                  Delhivery     ₹ 12,12,741          ₹436K       ₹11,274K   \n",
       "3                        IBM      ₹ 7,37,972          ₹569K        ₹2,648K   \n",
       "4         Ericsson-Worldwide      ₹ 7,15,984          ₹350K        ₹1,565K   \n",
       "5         UnitedHealth Group     ₹ 13,41,900        ₹1,037K        ₹1,500K   \n",
       "6         Valiance Solutions      ₹ 7,90,812          ₹487K        ₹1,421K   \n",
       "7                 Innovaccer     ₹ 11,81,047          ₹602K        ₹1,644K   \n",
       "8              ZS Associates      ₹ 9,89,924          ₹196K        ₹1,755K   \n",
       "9                EXL Service     ₹ 11,73,127          ₹558K        ₹1,500K   \n",
       "\n",
       "  Rating of the Company  \n",
       "0                    NA  \n",
       "1                    NA  \n",
       "2                    NA  \n",
       "3                    NA  \n",
       "4                    NA  \n",
       "5                    NA  \n",
       "6                    NA  \n",
       "7                    NA  \n",
       "8                    NA  \n",
       "9                    NA  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "gd_salary('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def flipkart_sunglasses(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sunglasses product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sunglass_brand_name=[]\n",
    "    sunglass_description=[]\n",
    "    sunglass_price=[]\n",
    "    sunglass_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sunglass_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sunglass_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sunglasses_flip=pd.DataFrame({})\n",
    "    sunglasses_flip['Product Brand']=sunglass_brand_name[:100]\n",
    "    sunglasses_flip['Product Description']=sunglass_description[:100]\n",
    "    sunglasses_flip['Price of Product']=sunglass_price[:100]\n",
    "    sunglasses_flip['Discount on Product']=sunglass_discount[:100]\n",
    "    return sunglasses_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (58)</td>\n",
       "      <td>₹485</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹209</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹666</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Over-sized ...</td>\n",
       "      <td>₹598</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (88)</td>\n",
       "      <td>₹255</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Cat-eye Sung...</td>\n",
       "      <td>₹358</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (58)</td>\n",
       "      <td>₹475</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Brand                                Product Description  \\\n",
       "0         Aislin    UV Protection, Gradient Cat-eye Sunglasses (58)   \n",
       "1         PIRASO         UV Protection Round Sunglasses (Free Size)   \n",
       "2       Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "3         PIRASO       UV Protection Aviator Sunglasses (Free Size)   \n",
       "4       Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..           ...                                                ...   \n",
       "95        GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "96        Aislin  UV Protection, Gradient Butterfly, Over-sized ...   \n",
       "97  Silver Kartz              UV Protection Aviator Sunglasses (88)   \n",
       "98        Aislin  UV Protection, Gradient Wayfarer, Cat-eye Sung...   \n",
       "99        Aislin             UV Protection Wayfarer Sunglasses (58)   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0              ₹485             68% off  \n",
       "1              ₹209             82% off  \n",
       "2              ₹499             50% off  \n",
       "3              ₹349             78% off  \n",
       "4              ₹666             16% off  \n",
       "..              ...                 ...  \n",
       "95             ₹349             82% off  \n",
       "96             ₹598             72% off  \n",
       "97             ₹255             78% off  \n",
       "98             ₹358             78% off  \n",
       "99             ₹475             77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "flipkart_sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def iphone_100_review(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s an amazing product from apple and the cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Upgraded from iphone 6 to 11 best phone for ip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>This will help you more. See if you are planni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5              Brilliant   \n",
       "1       5       Perfect product!   \n",
       "2       5      Worth every penny   \n",
       "3       5          Great product   \n",
       "4       5     Highly recommended   \n",
       "..    ...                    ...   \n",
       "95      5              Brilliant   \n",
       "96      5              Wonderful   \n",
       "97      5              Must buy!   \n",
       "98      5      Terrific purchase   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                         Full Reviews  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  I have migrated from OP 7pro... and trust me, ...  \n",
       "96  This is my first ever I phone. Before this I w...  \n",
       "97  It’s an amazing product from apple and the cam...  \n",
       "98  Upgraded from iphone 6 to 11 best phone for ip...  \n",
       "99  This will help you more. See if you are planni...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def flip_sneakers(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sneaker product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sneaker_brand_name=[]\n",
    "    sneaker_description=[]\n",
    "    sneaker_price=[]\n",
    "    sneaker_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sneaker_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sneaker_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sneaker_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sneaker_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sneakers_flipkart=pd.DataFrame({})\n",
    "    sneakers_flipkart['Brand Name']=sneaker_brand_name[:100]\n",
    "    sneakers_flipkart['Product Descriptions']=sneaker_description[:100]\n",
    "    sneakers_flipkart['Price']=sneaker_price[:100]\n",
    "    sneakers_flipkart['Discount %']=sneaker_discount[:100]\n",
    "    return sneakers_flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JEETLAV</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Speed Set of 5 Pairs Sneakers Outdoors Casuals...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ktiz</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹396</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jack Diamond</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹635</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bucik</td>\n",
       "      <td>Black Casual Shoes Synthetic Leather for Men S...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                               Product Descriptions Price  \\\n",
       "0        JEETLAV                                   Sneakers For Men  ₹349   \n",
       "1         BRUTON            Combo Pack Of 4 Casual Sneakers For Men  ₹424   \n",
       "2         Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...  ₹499   \n",
       "3   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men  ₹399   \n",
       "4         Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...  ₹474   \n",
       "..           ...                                                ...   ...   \n",
       "95        Chevit  Speed Set of 5 Pairs Sneakers Outdoors Casuals...  ₹759   \n",
       "96          Ktiz                                   Sneakers For Men  ₹399   \n",
       "97     ROCKFIELD                                   Sneakers For Men  ₹396   \n",
       "98  Jack Diamond                                   Sneakers For Men  ₹635   \n",
       "99         Bucik  Black Casual Shoes Synthetic Leather for Men S...  ₹749   \n",
       "\n",
       "   Discount %  \n",
       "0     65% off  \n",
       "1     89% off  \n",
       "2     72% off  \n",
       "3     60% off  \n",
       "4     76% off  \n",
       "..        ...  \n",
       "95    60% off  \n",
       "96    60% off  \n",
       "97    36% off  \n",
       "98    62% off  \n",
       "99    57% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "flip_sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Go to the link -\n",
    "https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def shoes_myntra(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    product_price=[]\n",
    "    \n",
    "    #Let's apply filter for price\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's apply filter for colour\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for q in brands:\n",
    "            brand_name.append(q.text)\n",
    "        \n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for q in descs:\n",
    "            description.append(q.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for q in prices:\n",
    "            product_price.append(q.text)\n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        time.sleep(5)\n",
    "        j+=1\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    myntra_shoes=pd.DataFrame({})\n",
    "    myntra_shoes['Brand of the Shoes']=brand_name[0:100]\n",
    "    myntra_shoes['Short Shoes Description']=description[0:100]\n",
    "    myntra_shoes['Price of the Shoes']=product_price[0:100]\n",
    "    return myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price of the Shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Superstar Sneakers</td>\n",
       "      <td>Rs. 8799Rs. 10999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Impulse Knit</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Woven-Design Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Monk Shoes</td>\n",
       "      <td>Rs. 9793Rs. 13990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand of the Shoes          Short Shoes Description  \\\n",
       "0       ADIDAS Originals           Men Superstar Sneakers   \n",
       "1                   Nike      Men JORDAN DELTA Basketball   \n",
       "2           UNDER ARMOUR         Men Charged Impulse Knit   \n",
       "3                   Puma                Men Running Shoes   \n",
       "4                   Nike     Men KD13 EP Basketball Shoes   \n",
       "..                   ...                              ...   \n",
       "95       PUMA Motorsport     Unisex Woven-Design Sneakers   \n",
       "96               Saint G       Women Leather Heeled Boots   \n",
       "97          Hush Puppies  Men Solid Leather Formal Derbys   \n",
       "98  Heel & Buckle London           Men Leather Monk Shoes   \n",
       "99  Heel & Buckle London              Women Leather Pumps   \n",
       "\n",
       "            Price of the Shoes  \n",
       "0   Rs. 8799Rs. 10999(20% OFF)  \n",
       "1                    Rs. 12495  \n",
       "2                     Rs. 8999  \n",
       "3                     Rs. 7499  \n",
       "4                    Rs. 12995  \n",
       "..                         ...  \n",
       "95                    Rs. 7999  \n",
       "96                    Rs. 9900  \n",
       "97                    Rs. 9999  \n",
       "98  Rs. 9793Rs. 13990(30% OFF)  \n",
       "99   Rs. 7192Rs. 8990(20% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "shoes=shoes_myntra('https://www.myntra.com/shoes')\n",
    "shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's call the Function Definition\n",
    "\n",
    "def laptop(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(r\"C:\\Webdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    item_title=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "    \n",
    "    #Let's search for laptop product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "        \n",
    "    #Let's apply filter for \"Intel Core i7\"\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's apply filter for \"Intel Core i9\"  \n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "        \n",
    "    # Let's scrape the data\n",
    "    titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for i in titles:\n",
    "        item_title.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "    for i in ratings:\n",
    "        rating.append(i.get_attribute('aria-label'))\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    amazon_laptops=pd.DataFrame({})\n",
    "    amazon_laptops['Title']=item_title[:10]\n",
    "    amazon_laptops['Price']=price[:10]\n",
    "    amazon_laptops['Rating']=rating[:10]\n",
    "    return amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI GL65 Leopard 10SDK-069IN Intel Core i7-107...</td>\n",
       "      <td>1,20,240</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,98,590</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2,77,390</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) HP EliteBook 820 G4 Laptop (CORE I5 ...</td>\n",
       "      <td>40,790</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>76,500</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>83,077</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>49,999</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>47,190</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price  \\\n",
       "0  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    86,990   \n",
       "1  MSI GL65 Leopard 10SDK-069IN Intel Core i7-107...  1,20,240   \n",
       "2  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,98,590   \n",
       "3  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  2,77,390   \n",
       "4  (Renewed) HP EliteBook 820 G4 Laptop (CORE I5 ...    40,790   \n",
       "5  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...    76,500   \n",
       "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    83,077   \n",
       "7  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...    49,999   \n",
       "8  Mi Notebook Horizon Edition 14 Intel Core i5-1...    47,190   \n",
       "9  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...  1,35,490   \n",
       "\n",
       "               Rating  \n",
       "0  4.6 out of 5 stars  \n",
       "1  3.0 out of 5 stars  \n",
       "2  3.0 out of 5 stars  \n",
       "3  3.3 out of 5 stars  \n",
       "4  4.6 out of 5 stars  \n",
       "5  4.1 out of 5 stars  \n",
       "6  4.3 out of 5 stars  \n",
       "7  1.0 out of 5 stars  \n",
       "8  4.3 out of 5 stars  \n",
       "9  3.0 out of 5 stars  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "laptop('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
